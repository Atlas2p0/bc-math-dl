{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31960fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import mlflow\n",
    "from PIL import Image\n",
    "from torchvision import datasets\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose\n",
    "import onnxruntime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "194904bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/22 17:57:29 WARNING mlflow.pytorch: Stored model version '2.8.0+cu126' does not match installed PyTorch version '2.5.1+cu121'\n"
     ]
    }
   ],
   "source": [
    "# Dirs\n",
    "cwd= os.getcwd()\n",
    "model_uri= os.path.join(cwd,\"../mlruns/0/models/m-e6eff4b8933a4b528f309d0afbc4474b/artifacts/\")\n",
    "loaded_model= mlflow.pytorch.load_model(model_uri)\n",
    "data_dir= os.path.join(cwd, \"../data\")\n",
    "artifacts_dir= os.path.join(cwd, \"../artifacts\")\n",
    "mlruns_dir= os.path.join(cwd, \"../mlruns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73782a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset= datasets.CIFAR100(root= data_dir, download= True, train= True)\n",
    "class_names= dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dceed94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: cockroach\n",
      "Confidence: 0.5041\n"
     ]
    }
   ],
   "source": [
    "def pytorch_inference(model, image_path, transforms, class_names, device):\n",
    "    try:\n",
    "        img= Image.open(image_path).convert('RGB')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found at {image_path}\")\n",
    "        return\n",
    "    \n",
    "    input_tensor= transforms(img)\n",
    "    input_batch= input_tensor.unsqueeze(0)\n",
    "    input_batch= input_batch.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output= model(input_batch)\n",
    "    \n",
    "    probabilities= F.softmax(output, dim= 1)\n",
    "    confidence, predicted_idx= torch.max(probabilities, 1)\n",
    "    predicted_class_name= class_names[predicted_idx.item()]\n",
    "    confidence_score= confidence.item()\n",
    "    print(f\"Predicted Class: {predicted_class_name}\")\n",
    "    print(f\"Confidence: {confidence_score:.4f}\")\n",
    "    return input_batch, output\n",
    "image_path= os.path.join(data_dir, \"test/test6.jpeg\")\n",
    "device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform= transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "input_tensor, torch_output= pytorch_inference(loaded_model, image_path, transform, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca7fb498",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.eval()\n",
    "onnx_model_path= os.path.join(artifacts_dir, \"resnet18_fft_dynamic.onnx\")\n",
    "torch.onnx.export(\n",
    "    loaded_model,\n",
    "    input_tensor,\n",
    "    onnx_model_path,\n",
    "    input_names=['x'],  \n",
    "    output_names=['output'],  # Standard for classifier logits\n",
    "    dynamic_axes={\n",
    "        'x': {0: 'batch_size'},  # Makes batch dim (index 0) dynamic (1-N)\n",
    "        'output': {0: 'batch_size'}  # Also dynamic for output\n",
    "    },\n",
    "    opset_version=11,  # Stable for ResNet18 (use 13+ if PyTorch 1.8+ for newer ops)\n",
    "    do_constant_folding=True,  # Optimizes constants (e.g., from normalization)\n",
    "    verbose=False  # Reduce logs; set True for debug\n",
    ")\n",
    "app_dir= os.path.join(cwd, \"../app/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051c3015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onnx_inference(onnx_path, image_path, transforms, class_names, device):\n",
    "    try:\n",
    "        img= Image.open(image_path).convert('RGB')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found at {image_path}\")\n",
    "        return\n",
    "    \n",
    "    input_tensor= transforms(img)\n",
    "    input_batch= input_tensor.unsqueeze(0)\n",
    "    input_batch= input_batch.to(device)\n",
    "\n",
    "    onnx_input= input_batch.numpy(force= True)\n",
    "    ort_session= onnxruntime.InferenceSession(onnx_path, providers= ['CPUExecutionProvider'])\n",
    "    onnx_runtime_input= {'x': onnx_input}\n",
    "    onnx_runtime_output= ort_session.run(None, onnx_runtime_input)[0]\n",
    "    onnx_tensor_output= torch.tensor(onnx_runtime_output)\n",
    "    onnx_probs= F.softmax(onnx_tensor_output, dim= 1)\n",
    "    onnx_confidence, onnx_pred_idx= torch.max(onnx_probs, 1)\n",
    "    print(f\"Prediction: {class_names[onnx_pred_idx]} | Confidence: {onnx_confidence.item():.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8c925a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: cockroach | Confidence: 0.5044\n"
     ]
    }
   ],
   "source": [
    "onnx_model_path= os.path.join(artifacts_dir, \"resnet18_fft.onnx\")\n",
    "onnx_inference(onnx_model_path, image_path, transform, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f1dd1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping= {i: class_name for i, class_name in enumerate(class_names)}\n",
    "label_file_path= os.path.join(artifacts_dir + \"/label_mapping.json\")\n",
    "with open(label_file_path, 'w') as f:\n",
    "    json.dump(label_mapping, f, indent= 4)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_complete_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
